WEEK 3 DEVELOPMENT LOG
Date Range: November 17-23, 2025
Project: SOTA Small Networks Comparison (CAP6415)






===========================================
November 17, 2025 - Data Loader Implementation
===========================================

Implemented data loading pipeline for all three datasets:

1. CIFAR-100 Loader (get_cifar100_loaders):
   - Using torchvision.datasets.CIFAR100 for easy loading
   - Auto-download feature included
   - Split: 45000 train / 5000 val / 10000 test
   - Batch size: 128 (from config)
   - Works perfectly out of the box

2. Stanford Dogs Loader (get_stanford_dogs_loaders):
   - Had to figure out the nested folder structure
   - Images located at: datasets/stanford_dogs/Images/breed_folder/Images/
   - Using ImageFolder since breeds are in separate folders
   - Found 20,580 images across 120 dog breeds
   - Split: 70% train / 15% val / 15% test (14405/3087/3088)
   - Batch size: 32 (from config)

3. Flowers-102 Loader (get_flowers102_loaders):
   - Custom Dataset class needed to parse .mat files
   - imagelabels.mat contains labels (converted from 1-indexed to 0-indexed)
   - setid.mat contains train/val/test split indices
   - Images named as image_00001.jpg, image_00002.jpg, etc.
   - Split: 1020 train / 1020 val / 6149 test (official splits)
   - Batch size: 32 (from config)

Key Implementation Details:
- Created utils/ directory and utils/__init__.py
- get_transforms() handles train vs test augmentation
- Training augmentation: RandomResizedCrop, RandomHorizontalFlip, ColorJitter, RandomRotation
- Test augmentation: Resize, CenterCrop (no random stuff)
- All images normalized with ImageNet statistics (for transfer learning)
- get_dataloaders() is the main function - just pass dataset name
- Added load_config() to read from configs/config.yaml

Testing:
- All three data loaders tested successfully
- Created test_dataloaders.py for quick verification
- Verified batch shapes: torch.Size([batch_size, 3, 224, 224])
- All images properly resized to 224x224 as expected

Notes/Issues:
- Got some warnings about pynvml being deprecated (not critical)
- MPS (Apple Silicon) doesn't support pin_memory yet (minor warning)
- Stanford Dogs folder structure was confusing at first but figured it out
- Flowers-102 .mat files use 1-based indexing (had to subtract 1)

Files Created:
- utils/__init__.py
- utils/data_loader.py
- test_dataloaders.py

Next Steps (for rest of week):
- Implement model loading (mobilenetv3, efficientnet, shufflenet, squeezenet)
- Create training loop with basic functionality
- Test 2-3 epoch run on CIFAR-100

===========================================
Manual Verification Test - November 17, 2025
===========================================

Ran: python utils/data_loader.py

Test Results:
CIFAR-100 works!
  - Batch shape: torch.Size([128, 3, 224, 224])
  - Labels shape: torch.Size([128])
  - Train/Val/Test: 45000/5000/10000 samples

Stanford Dogs works!
  - Batch shape: torch.Size([32, 3, 224, 224])
  - Labels shape: torch.Size([32])
  - Train/Val/Test: 14405/3087/3088 samples

Flowers-102 works!
  - Batch shape: torch.Size([32, 3, 224, 224])
  - Labels shape: torch.Size([32])
  - Train/Val/Test: 1020/1020/6149 samples

All data loaders verified working correctly.
Minor warnings about pynvml deprecation and MPS pin_memory - not affecting functionality.

===========================================
November 17, 2025 - Model Implementation
===========================================

Implemented model loading wrappers for all 4 architectures:

1. MobileNetV3-Small (get_mobilenetv3):
   - Using torchvision.models.mobilenet_v3_small
   - Final layer at model.classifier[3] (Linear layer)
   - Replace: 1024 -> num_classes
   - Parameters: 1,620,356 (6.18 MB for 100 classes)
   - Supports pretrained ImageNet weights

2. EfficientNet-B0 (get_efficientnet):
   - Using timm.create_model('efficientnet_b0')
   - timm handles classifier replacement automatically
   - Parameters: 4,135,648 (15.78 MB for 100 classes)
   - Easiest to implement since timm does the work

3. ShuffleNetV2 0.5x (get_shufflenet):
   - Using torchvision.models.shufflenet_v2_x0_5
   - Final layer at model.fc (Linear layer)
   - Replace: 1024 -> num_classes
   - Parameters: 444,292 (1.69 MB for 100 classes)
   - Smallest model of the four

4. SqueezeNet 1.1 (get_squeezenet):
   - Using torchvision.models.squeezenet1_1
   - Uses Conv2d as final classifier (unusual design)
   - Final layer at model.classifier[1]
   - Replace: Conv2d(512, 1000) -> Conv2d(512, num_classes)
   - Parameters: 773,796 (2.95 MB for 100 classes)

Key Implementation Details:
- Created get_model() unified interface
- Supports pretrained weights loading (pretrained=True/False)
- Automatically replaces final layers based on num_classes
- Added count_parameters() and print_model_summary() utilities
- All models return proper output shape: [batch_size, num_classes]

Testing Results:
- Tested all 4 models with all 3 datasets (100, 120, 102 classes)
- Forward pass verification: All models produce correct output shapes
- CIFAR-100: All models output [128, 100] - OK
- Stanford Dogs: All models output [32, 120] - OK
- Flowers-102: All models output [32, 102] - OK
- Pretrained weights loading: All models load successfully

Model Size Comparison (for 100 classes):
- ShuffleNetV2: 1.69 MB (smallest)
- SqueezeNet: 2.95 MB
- MobileNetV3: 6.18 MB
- EfficientNet: 15.78 MB (largest)

Files Created:
- models/__init__.py (updated with all model loaders)
- test_models.py (comprehensive test suite)

Notes:
- SqueezeNet's Conv2d classifier is different from others
- EfficientNet is larger but supposedly more efficient per parameter
- ShuffleNet is the smallest, good for extreme resource constraints
- All models tested with both pretrained=True and pretrained=False